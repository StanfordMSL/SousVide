from turtle import width
import numpy as np
import json
import os
from typing import Dict,Union,Tuple,List
from tqdm.notebook import trange

from controller.vr_mpc import VehicleRateMPC
from controller.pilot import Pilot
import dynamics.quadcopter_config as qc
import dynamics.quadcopter_simulate as qs
import synthesize.trajectory_helper as th
import synthesize.nerf_utils as nf
import synthesize.data_utils as du
import torch

from synthesize.solvers import (
    min_snap as ms,
)

def generate_rollout_data(cohort:str,courses:List[str],drone:str,method:str,
                          nerf:nf.NeRF,
                          Nro_tp:int,
                          Nro_sv:int=100,
                          Ntp_sc:int=10):
    
    """
    Generates flight data for a given cohort. A cohort comprises a set of courses flown on a specific
    drone frame with a specific method of domain randomization. Flight data is agnostic to the pilot 
    and is generated by simulating variations of the drone over the set of courses using an MPC flight
    controller that has full knowledge. The flight data is saved to a .pt file in the cohort directory.

    Args:
        cohort:         Name of the cohort.
        courses:        Names of courses.
        drone:          Name of the drone.
        method:         Name of the method.
        nerf:           NeRF model.
        Nro_tp:         Number of rollouts per time point.
        Nro_sv:         Number of rollouts per save.
        Ntp_sc:         Number of time points per second.
        batch_size:     Number of rollouts to generate in a single batch.
        plot_sample_size:  Number of sample flights to plot per course.

    Returns:
        None:           (flight data saved to cohort directory)
    """

    # Some useful path(s)
    workspace_path = os.path.dirname(
        os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
    
    # Load drone and method configs
    cohort_path = os.path.join(workspace_path,"cohorts",cohort)
    drone_path  = os.path.join(workspace_path,"configs","drones",drone+".json")
    method_path = os.path.join(workspace_path,"configs","methods",method+".json")

    with open(drone_path) as json_file:
        drone_config = json.load(json_file)
    with open(method_path) as json_file:
        method_config = json.load(json_file)
        sample_set_config = method_config["sample_set"]
        trajectory_set_config = method_config["trajectory_set"]
        drone_set_config = method_config["drone_set"]
        
    # Create cohort directory (if it does not exist)
    if not os.path.exists(cohort_path):
        os.makedirs(cohort_path)

    # Generate base drone configuration
    base_drone_config = qc.generate_preset_config(drone_config)

    # Print some useful information
    print("==========================================================================")
    print("Cohort :",cohort)
    print("Method :",method)
    print("Drone  :",drone)
    print("Courses:",courses)

    # Generate rollouts for each course
    for course in courses:
        # Load course_config
        course_path = os.path.join(workspace_path,"configs","courses",course+".json")

        with open(course_path) as json_file:
            course_config = json.load(json_file)

        # Generate ideal trajectory
        Tpi,CPi = ms.solve(course_config)
        tXUi = th.ts_to_tXU(Tpi,CPi,base_drone_config)

        # Generate Sample Set Batches
        Ntp = Ntp_sc*int(Tpi[-1])                                       # Number of time points per trajectory
        Nsp = Nro_tp*Ntp                                                # Number of sample points (total)
        
        Tsp = np.tile(np.linspace(Tpi[0],Tpi[-1],Ntp+1)[:-1],Nro_tp)    # Entire sample points array
        Tsp += np.random.uniform(-1/Ntp_sc,1/Ntp_sc,Nsp)                # Add some noise to the sample points array
        Tsp = np.clip(Tsp,Tpi[0],Tpi[-1])                               # Clip the sample points array
        np.random.shuffle(Tsp)                                          # Shuffle the sample points array

        TTsp = np.split(Tsp,np.arange(Nro_sv,Nsp,Nro_sv))               # Split the sample points array into their batches
        
        # Print some diagnostics
        Ndc = int(sample_set_config["rollout_duration"]*sample_set_config["simulation"]["hz_ctl"])

        print("--------------------------------------------------------------------------")
        print("Course Name :",course)
        print("Rollout Reps:",Nro_tp,"(per time point)")
        print("Rollout Rate:",Ntp_sc,"(per second)")
        print("Rollout Data:",Ndc,"(per sample)")
        print("Sample Size :",Nsp,"(total)")
        print("Batch Sizes :", len(TTsp)-1, "x", Nro_sv,"+ 1 x", len(TTsp[-1]),"(samples)")

        # Generate Sample Set Batches
        Ndata = 0
        for idx in trange(len(TTsp)):
            # Get the current batch
            Tsp = TTsp[idx]
            
            # Generate sample drones
            Drones = generate_drones(len(Tsp),drone_set_config,base_drone_config)

            # Generate sample perturbations
            Perturbations  = generate_perturbations(Tsp,trajectory_set_config,Tpi,CPi)

            # Generate rollout data
            Trajectories,Images = generate_rollouts(course_config,sample_set_config,nerf,Drones,Perturbations)

            # Save the rollout data
            du.save_rollouts(cohort,course,Trajectories,Images,tXUi,idx)

            # Update the data count
            Ndata += sum([trajectory["Ndata"] for trajectory in Trajectories])

        # Print some diagnostics
        print("--------------------------------------------------------------------------")
        print("Generated ",Ndata," points of data.")
        print("--------------------------------------------------------------------------")

def generate_observation_data(cohort:str,roster:List[str],subsample:float=1.0):
    """
    Takes rollout data and generates observations for each pilot in the cohort. The observations are
    generated by running the rollout data through the pilot's OODA function. The observations are saved
    to a .pt file in the pilot's directory.

    """
    
    # Generate some useful paths
    workspace_path = os.path.dirname(
        os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
    cohort_path = os.path.join(workspace_path,"cohorts",cohort)
    rollout_folder_path = os.path.join(cohort_path,"rollout_data")

    # Initialize Pilots
    Pilots = [Pilot(cohort,name) for name in roster]

    for pilot in Pilots:
        # Print some useful information
        print("==========================================================================================")
        print("------------------------------------------------------------------------------------------")
        print(f"Pilot Name  : {pilot.name}")
        print(f"Augmentation: {pilot.da_cfg['mean']}")
        print( "            :                        +/-")
        print(f"            : {pilot.da_cfg['std']}")
        print(f"Subsample   : 1 in {int(1/subsample)}")
        print("Model ------------------------------------------------------------------------------------")
        print(f"Name        : {pilot.model.name}")
        print( "Components  :", ','.join(pilot.model.network.keys()))
        print("------------------------------------------------------------------------------------------")

        # Get Course Folders
        courses = [folder for folder in os.listdir(rollout_folder_path)]
        
        Nobs = 0
        for course in courses:
            # Load Trajectory Data
            rollout_data_path = os.path.join(rollout_folder_path,course)
            trajectory_data_files = sorted([
                file for file in os.listdir(rollout_data_path)
                if file.startswith("trajectories") and file.endswith(".pt")])
            image_data_files = sorted([
                file for file in os.listdir(rollout_data_path)
                if file.startswith("images") and file.endswith(".pt")])
            
            # Generate Observation Data (sans images)
            for trajectory_data_file,image_data_file in zip(trajectory_data_files,image_data_files):
                trajectory_data_set = torch.load(os.path.join(rollout_data_path,trajectory_data_file))
                image_data_set = torch.load(os.path.join(rollout_data_path,image_data_file))
                observations = generate_observations(pilot,trajectory_data_set,image_data_set,subsample)
                Nobs += observations["Nobs"]

                # Save the observations
                du.save_observations(cohort,course,pilot.name,observations)

        print("Data Counts ------------------------------------------------------------------------------")
        print("Extracted",Nobs,"observations from",len(courses),"course(s).")
    print("==========================================================================================")

def generate_drones(Nsps:int,
                    drone_set_config:Dict[str,Union[float,list]],
                    drone_base_config:Dict[str,Union[np.ndarray,str,int,float]],
                    rng_seed:Union[int,None]=None) -> List[Dict[str,Union[np.ndarray,str,int,float]]]:
    
    """
    Generates a list of drone variations for a given base drone configuration. The configurations are
    generated by perturbing the base drone configuration with bounded uniform noise. The number of
    configurations generated is determined by the sample set config dictionary.

    Args:
        Nsps:                     Number of drones to generate.
        drone_set_config:       Drone set config dictionary.
        drone_base_config:      Base drone configuration dictionary.
        rng_seed:               Random number generator seed.

    Returns:
        Drones:                 List of drone configurations (dictionary format).
    """

    # Set random number generator seed
    if rng_seed is not None:
        np.random.seed(rng_seed)

    m   = np.array(drone_base_config["m"])
    Imp = np.diag(drone_base_config["I"])/m
    lf  = np.array(drone_base_config["lf"])
    lb  = np.array(drone_base_config["lb"])
    fn  = np.array(drone_base_config["fn"])
    tg  = np.array(drone_base_config["tg"])

    w_m  = np.array(drone_set_config["mass"],dtype=float)
    w_I  = np.array(drone_set_config["inertia"],dtype=float)
    w_lf = np.array(drone_set_config["arm_front"],dtype=float)
    w_lb = np.array(drone_set_config["arm_back"],dtype=float)
    w_fn = np.array(drone_set_config["force_normalized"],dtype=float)
    w_tg = np.array(drone_set_config["torque_gain"],dtype=float)

    # Compute bounds
    m_bnd   = [m*(1-w_m),m*(1+w_m)]
    Imp_bnd = [Imp*(1-w_I),Imp*(1+w_I)]
    lf_bnd  = [lf*(1-w_lf),lf*(1+w_lf)]
    lb_bnd  = [lb*(1-w_lb),lb*(1+w_lb)]
    fn_bnd  = [fn*(1-w_fn),fn*(1+w_fn)]
    tg_bnd  = [tg*(1-w_tg),tg*(1+w_tg)]

    # # FIXME: Revert back to percentages
    # m_bnd = [m-w_m,m+w_m]
    # fn_bnd = [fn-w_fn,fn+w_fn]

    # Generate Drone Frames
    Drones = []
    for _ in range(Nsps):
        m = np.random.uniform(*m_bnd)
        Imp = np.random.uniform(*Imp_bnd)
        lf = np.random.uniform(*lf_bnd)
        lb = np.random.uniform(*lb_bnd)
        fn = np.random.uniform(*fn_bnd)
        tg = np.random.uniform(*tg_bnd)

        # Save to a dictionary
        quad = qc.generate_config(m,Imp,lf,lb,fn,tg)
        Drones.append(quad)

    return Drones

def generate_perturbations(Tsps:np.ndarray,
                           trajectory_set_config:Dict[str,Union[int,bool]],
                           Tpi:np.ndarray,CPi:np.ndarray,
                           rng_seed:int=None) -> List[Dict[str,Union[float,np.ndarray]]]:
    """
    Generates a list of perturbed initial states for the drone given an ideal trajectory. The perturbed
    initial states are generated by sampling a random initial times and corresponding state vectors from
    the ideal trajectory using a bounded uniform distribution. The state vectors are then perturbed with
    uniform noise. The number of perturbed initial states generated is determined by the sample set
    config dictionary.

    Args:
        Tsps:                   Sample times.
        trajectory_set_config:  Trajectory set config dictionary.
        Tpi:                    Ideal trajectory times.
        CPi:                    Ideal trajectory control points.
        rng_seed:               Random number generator seed.

    Returns:
        Perturbations:          List of perturbations (dictionary format).
    """

    # Unpack the trajectory
    Nsps = len(Tsps)

    # Set random number generator seed
    if rng_seed is not None:
        np.random.seed(rng_seed)
    
    # Unpack the config
    w_x0 = np.array(trajectory_set_config["initial"],dtype=float)
    
    # Get ideal trajectory for quaternion checking
    tXUi = th.ts_to_tXU(Tpi,CPi,None,10)

    # Generate perturbed starting points    
    Perturbations = []
    for i in range(Nsps):
        # Sample random start time and get corresponding state vector sample
        t0 = Tsps[i]
        idx0 = np.where(Tpi <= t0)[0][-1]
        idx0 = min(idx0,(len(Tpi)-2))
        t00,t0f = Tpi[idx0],Tpi[idx0 + 1]

        x0s = th.ts_to_xu(t0-t00,t0f-t00,CPi[idx0,:,:],None)[0:10]
        
        # Perturb state vector sample
        w0 = np.random.uniform(w_x0[0,:],w_x0[1,:])
        x0 = x0s + w0
        
        # Ensure quaternion is well-behaved (magnitude and closest to previous)
        idxr = np.where(tXUi[0,:] <= t0)[0][-1]
        x0[6:10] = th.obedient_quaternion(x0[6:10],tXUi[7:11,idxr])

        # Store perturbation in list
        perturbation = {"t0":t0,"x0":x0}
        Perturbations.append(perturbation)
    
    return Perturbations

def generate_rollouts(
        course_config:Dict[str,Dict[str,Union[float,np.ndarray]]],
        sample_set_config:Dict[str,Union[int,bool]],
        nerf:nf.NeRF,
        Drones:Dict[str,Union[np.ndarray,str,int,float]],
        Perturbations:Dict[str,Union[float,np.ndarray]]
        ) -> Tuple[List[Dict[str,Union[np.ndarray,np.ndarray,np.ndarray]]],List[torch.Tensor]]:
    """
    Generates rollout data for the quadcopter given a list of drones and initial states (perturbations).
    The rollout comprises trajectory data and image data. The trajectory data is generated by running
    the MPC controller on the quadcopter for a fixed number of steps. The trajectory data consists of
    time, states [p,v,q], body rate inputs [fn,w], objective state, data count, solver timings, advisor
    data, rollout id, and course name. The image data is generated by rendering the quadcopter at each
    state in the trajectory data. The image data consists of the image data and the data count.

    Args:
        course_config:          Course config dictionary.
        sample_set_config:      Sample set config dictionary.
        nerf:                   NeRF model.
        Drones:          List of drone configurations.
        Perturbations:          List of perturbed initial states.

    Returns:
        Trajectories:           List of trajectory rollouts.
        Images:                 List of image rollouts.
    """

    # Unpack sample set config
    mu_md = np.array(sample_set_config["model_noise"]["mean"])
    std_md = np.array(sample_set_config["model_noise"]["std"])
    mu_sn = np.array(sample_set_config["sensor_noise"]["mean"])
    std_sn = np.array(sample_set_config["sensor_noise"]["std"])
    hz_ctl = sample_set_config["simulation"]["hz_ctl"]
    hz_sim = sample_set_config["simulation"]["hz_sim"]
    t_dly = sample_set_config["simulation"]["delay"]
    dt_ro = sample_set_config["rollout_duration"]
    
    # Unpack the trajectory
    Tpi,CPi = ms.solve(course_config)
    obj = th.ts_to_obj(Tpi,CPi)

    # Initialize rollout variables
    Trajectories,Images = [],[]

    # Rollout the trajectories
    for idx,(drone,perturbation) in enumerate(zip(Drones,Perturbations)):
        # Unpack rollout variables
        t0,x0 = perturbation["t0"],perturbation["x0"]
        tf = t0 + dt_ro

        # Some useful intermediate variables
        policy = VehicleRateMPC(course_config,drone,hz_ctl)
        simulator = policy.generate_simulator(hz_sim)

        # Simulate the flight
        Tro,Xro,Uro,Imgs,Tsol,Adv = qs.simulate_flight(policy,simulator,
                                                       t0,tf,x0,obj,nerf,hz_sim,
                                                       mu_md=mu_md,std_md=std_md,
                                                       mu_sn=mu_sn,std_sn=std_sn,
                                                       t_dly=t_dly)
        
        # TODO: either make Xid from Tpi,CPi or maybe it's ok to leave it blank?
        trajectory = {
            "Tro":Tro,"Xro":Xro,"Uro":Uro,
            "Xid":None,"obj":obj,"Ndata":Uro.shape[1],"Tsol":Tsol,"Adv":Adv,
            "rollout_id":str(idx).zfill(5),
            "course":course_config["name"],
            "drone":drone}

        images = {
            "images":Imgs,
            "rollout_id":str(idx).zfill(5),"course":course_config["name"]
        }

        # Store rollout data
        Trajectories.append(trajectory)
        Images.append(images)

        # Delete the generated code
        policy.clear_generated_code()

    return Trajectories,Images

def generate_observations(pilot:Pilot,
                            trajectory_data_set:Dict[str,Union[str,int,Dict[str,Union[np.ndarray,float,str]]]],
                            image_data_set:Dict[str,Union[str,int,Dict[str,Union[np.ndarray,float,str]]]],
                            subsample:float=1) -> Dict[str,Union[str,int,Dict[str,Union[np.ndarray,float,str]]]]:
    
    # Initialize the observation data dictionary
    Observations = []

    # Unpack augmenteation variables
    aug_type = np.array(pilot.da_cfg["type"])
    aug_mean = np.array(pilot.da_cfg["mean"])
    aug_std = np.array(pilot.da_cfg["std"])

    # Set subsample step
    nss = int(1/subsample)

    # Generate observations
    Nobs = 0
    for trajectory_data,image_data in zip(trajectory_data_set["data"],image_data_set["data"]):
        # Unpack data
        Tro,Xro,Uro = trajectory_data["Tro"],trajectory_data["Xro"],trajectory_data["Uro"]
        obj,Ndata = trajectory_data["obj"],trajectory_data["Ndata"]
        rollout_id,course = trajectory_data["rollout_id"],trajectory_data["course"]
        drone = trajectory_data["drone"]

        # Decompress and extract the image data
        test = du.decompress_data(image_data)
        Imgs = du.decompress_data(image_data)["images"]

        # Check if images are raw or processed. Raw images are in (N,H,W,C) format while
        # processed images are in (N,C,H,W) format.
        height,width = Imgs.shape[1],Imgs.shape[2]

        if height == 224 and width == 224:
            Imgs = np.transpose(Imgs, (0, 3, 1, 2))

        # Create Rollout Data
        Xnn,Ynn = [],[]
        upr = np.zeros(4)
        znn_cr = torch.zeros(pilot.model.Nz).to(pilot.device)
        for k in range(Ndata):
            # Generate current state (with/without noise augmentation)
            if aug_type == "additive":
                xcr = Xro[:,k] + np.random.normal(aug_mean,aug_std)
            elif aug_type == "multiplicative":
                xcr = Xro[:,k] * (1 + np.random.normal(aug_mean,aug_std))
            else:
                xcr = Xro[:,k]

            # Extract other data
            tcr = Tro[k]
            ucr = Uro[:,k]
            img_cr = Imgs[k,:,:,:]

            # Generate the sfti data
            _,znn_cr,_,xnn,_ = pilot.OODA(upr,tcr,xcr,obj,img_cr,znn_cr)
            ynn = {"unn":ucr,"mfn":np.array([drone["m"],drone["fn"]]),"onn":xcr}

            # Store the data
            if k % nss == 0:
                Xnn.append(xnn)
                Ynn.append(ynn)

            # Loop updates
            upr = ucr

        # Store the observation data
        observations = {
            "Xnn":Xnn,
            "Ynn":Ynn,
            "Ndata":len(Xnn),
            "rollout_id":rollout_id,
            "course":course,"drone":drone
        }
        Observations.append(observations)
        Nobs += len(Xnn)

    observations_data_set = {"data":Observations,
                    "set":trajectory_data_set["set"],
                    "Nobs":Nobs,
                    "course":trajectory_data_set["course"]}

    return observations_data_set